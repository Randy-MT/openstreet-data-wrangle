{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27a87d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pprint\n",
    "import os\n",
    "\n",
    "import csv\n",
    "import codecs\n",
    "import xml.etree.cElementTree as ET\n",
    "import requests\n",
    "import cerberus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ab5f40",
   "metadata": {},
   "source": [
    "## Data import and sample file creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0db14e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesize is 111 Megabytes\n"
     ]
    }
   ],
   "source": [
    "k = 10 # Parameter: take every k-th top level element\n",
    "\n",
    "OSM_FILE = \"SEA_map.osm\" \n",
    "OSM_PATH = \"sample.osm\"\n",
    "os.chdir(r\"C:\\Users\\randy\\OneDrive\\Desktop\\Udacity\\Wrangle OpenStreetMap Data\")\n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "            \n",
    "with open(OSM_PATH, 'wb') as output:\n",
    "    output.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    output.write('<osm>\\n  ')\n",
    "\n",
    "    # Write every kth top level element\n",
    "    for i, element in enumerate(get_element(OSM_FILE)):\n",
    "        if i % k == 0:\n",
    "            output.write(ET.tostring(element, encoding='utf-8'))\n",
    "\n",
    "    output.write('</osm>')\n",
    "    \n",
    "print 'Filesize is',int(os.stat(OSM_PATH).st_size / 2**20), 'Megabytes'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cce6beb",
   "metadata": {},
   "source": [
    "## Investigate the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d14a688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lower': 168344, 'lower_colon': 164731, 'other': 3363, 'problemchars': 0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "def key_type(element, keys):\n",
    "    \"\"\" Identify and count characters/symbols within tags \"\"\"\n",
    "    if element.tag == \"tag\":\n",
    "        if lower.search(element.attrib['k']):\n",
    "            keys['lower'] += 1\n",
    "        elif lower_colon.search(element.attrib['k']):\n",
    "            keys['lower_colon'] += 1\n",
    "        elif problemchars.search(element.attrib['k']):\n",
    "            keys['problemchars'] += 1\n",
    "        else:\n",
    "            keys['other'] += 1        \n",
    "    return keys\n",
    "\n",
    "def key_type_process_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "    return keys\n",
    "key_type_process_map(OSM_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17dad299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2710"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Find unique users\n",
    "def get_user(filename, element):\n",
    "    \"\"\" Find the total number of unique users within the dataset \"\"\"\n",
    "    users = set()\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        for node in element:\n",
    "            for key, value in (node.attrib).items():\n",
    "                if key == 'uid':\n",
    "                    users.add(value)\n",
    "    return len(users)\n",
    "    \n",
    "get_user(OSM_PATH,element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1af8e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'node': 484425, 'nd': 557796, 'member': 17901, 'tag': 336438, 'relation': 727, 'way': 63381, 'osm': 1}\n"
     ]
    }
   ],
   "source": [
    "def count_tags(filename):\n",
    "    \"\"\" Count the total numbers of each tag type within the dataset \"\"\"\n",
    "    tags={}\n",
    "    for event, elem in ET.iterparse(filename, events=(\"start\",)):  \n",
    "        if elem.tag not in tags.keys():\n",
    "            tags[elem.tag]=1\n",
    "        else:\n",
    "            tags[elem.tag] = tags[elem.tag]+1\n",
    "            \n",
    "    return tags \n",
    "\n",
    "tag_count = count_tags(OSM_PATH)\n",
    "print tag_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd90dfe",
   "metadata": {},
   "source": [
    "## Data Auditing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d9b394e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streets to be corrected\n",
      "{'305': set(['State Highway 305']),\n",
      " 'Alley': set(['Post Alley']),\n",
      " 'Ave': set(['3131 Elliot Ave']),\n",
      " 'Blvd': set(['NW Gilman Blvd']),\n",
      " 'Blvd.': set(['Northwest Gilman Blvd.']),\n",
      " 'Broadway': set(['Broadway']),\n",
      " 'Center': set(['Parkplace Center']),\n",
      " 'Dr': set(['SE Mile Hill Dr']),\n",
      " 'Esplanade': set(['Northwest Esplanade']),\n",
      " 'Highway': set(['Maple Valley Highway', 'West Valley Highway']),\n",
      " 'Key': set(['Skagit Key']),\n",
      " 'Mall': set(['Southcenter Mall']),\n",
      " 'N': set(['Bronson Way N', 'Madison Ave N']),\n",
      " 'NE': set(['116th Ave NE',\n",
      "            '140th Ave NE',\n",
      "            '140th Avenue NE',\n",
      "            '148th Ave NE',\n",
      "            '155th Place NE',\n",
      "            '156th Pl NE',\n",
      "            '156th Place NE',\n",
      "            '157th Place NE',\n",
      "            '161st Ave NE',\n",
      "            '176th Ave NE',\n",
      "            '180th Place NE',\n",
      "            '233rd Pl NE',\n",
      "            '234th Place NE',\n",
      "            '236th Ave NE',\n",
      "            'Bellevue Way NE',\n",
      "            'Woodson Ln NE']),\n",
      " 'NW': set(['Newport Way NW', 'Pacific Crest Pl NW']),\n",
      " 'Northest': set(['169th Avenue Northest']),\n",
      " 'PL': set(['NE 16th PL']),\n",
      " 'Point': set(['Carillon Point']),\n",
      " 'S': set(['Wells Ave S']),\n",
      " 'SE': set(['112th Avenue SE', '118th Ave SE', '119TH AVE SE', '230 Lane SE']),\n",
      " 'St': set(['NE 11th St', 'NE 24th St', 'NE 35th St', 'Vine St']),\n",
      " 'Vista': set(['Northeast Sunrise Vista']),\n",
      " 'avenue': set(['Ericksen avenue'])}\n",
      "\n",
      "mph abbreviations to be corrected\n",
      "{'10': set(['10']),\n",
      " '16': set(['16']),\n",
      " '20': set(['20']),\n",
      " '25': set(['25']),\n",
      " '32': set(['32']),\n",
      " '48': set(['48'])}\n",
      "\n",
      "post codes to be corrected\n",
      "{'98027-3819': set(['98027-3819']),\n",
      " '98052-4176': set(['98052-4176']),\n",
      " '98133-6124': set(['98133-6124']),\n",
      " '98146-3152': set(['98146-3152']),\n",
      " '98146-3169': set(['98146-3169']),\n",
      " '98166-1809': set(['98166-1809']),\n",
      " '98166-1811;98166': set(['98166-1811;98166']),\n",
      " '98166-1848': set(['98166-1848']),\n",
      " '98166-1917': set(['98166-1917']),\n",
      " '98166-2208': set(['98166-2208']),\n",
      " '98166-2624': set(['98166-2624']),\n",
      " '98166-4601': set(['98166-4601']),\n",
      " '98166-4614': set(['98166-4614']),\n",
      " '98166;98166-1924': set(['98166;98166-1924'])}\n",
      "\n",
      "name direction suffix to be corrected\n",
      "{'N; SE': set(['N; SE']),\n",
      " 'NW; SE': set(['NW; SE']),\n",
      " 'SE; NE': set(['SE; NE']),\n",
      " 'SE;NE': set(['SE;NE'])}\n"
     ]
    }
   ],
   "source": [
    "street_type_re = re.compile(r'\\S+\\.?$', re.IGNORECASE)\n",
    "speed_limit_re = re.compile(r'\\S(\\w+)$', re.IGNORECASE) # regex to capture last word\n",
    "street_types = defaultdict(set)\n",
    "speed_limits = defaultdict(set)\n",
    "post_codes = defaultdict(set)\n",
    "name_directions = defaultdict(set)\n",
    "\n",
    "expected = [\"Street\",\"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\",\"North\",\"Northeast\",\"Northwest\",\"Southeast\",\"Southwest\",\n",
    "            \"South\",\"Way\",\"West\",\"Circle\",\"East\",\"D\",\"Loop\",\"Plaza\",\"Terrace\"]\n",
    "\n",
    "mapping = {\"NE\": \"Northeast\",\"St\": \"Street\",\"St.\": \"Street\",\"Blvd.\": \"Boulevard\",'Blvd':\"Boulevard\",\"SE\": \"Southeast\",\n",
    "           \"Northest\": \"Northeast\",\"Dr\": \"Drive\",\"E\": \"East\",\"Ave\":\"Avenue\",'avenue':\"Avenue\",\"PL\":\"Place\",'N':\"North\",\n",
    "           'NW':\"Northwest\",'S':\"South\"}\n",
    "\n",
    "#########################\n",
    "## Tag locate\n",
    "#########################\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "def is_post_code(elem):\n",
    "    return (elem.attrib['k'] == \"addr:postcode\")\n",
    "\n",
    "def is_speed_limit(elem):\n",
    "    return (elem.attrib['k'] == \"maxspeed\")\n",
    "\n",
    "def is_direction_suffix(elem):\n",
    "    return (elem.attrib['k'] == \"tiger:name_direction_suffix\")\n",
    "\n",
    "def is_timestamp(elem):\n",
    "    return (elem == \"timestamp\")\n",
    "\n",
    "##########################\n",
    "## audits\n",
    "##########################\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "def audit_speed_limit(speed_limits,speed_name):\n",
    "    s = speed_limit_re.search(speed_name)\n",
    "    if s:\n",
    "        speed_name = s.group()\n",
    "        if speed_name != \"mph\":\n",
    "            speed_limits[speed_name].add(speed_name)\n",
    "        \n",
    "def audit_post_code(post_codes,post_code):\n",
    "    expected = int(5)\n",
    "    if len(post_code) != expected:\n",
    "        post_codes[post_code].add(post_code)\n",
    "        \n",
    "def audit_direction_suffix(name_directions,suffix):  # some k tags have multiple streets assigned to them, as such multiple suffix values can appear\n",
    "    expected = ['N','NE','NW','W','E','NE','S','SE','SW']\n",
    "    if suffix not in expected:\n",
    "        name_directions[suffix].add(suffix)\n",
    "        \n",
    "def audit(filename):\n",
    "    for event, elem in ET.iterparse(filename):\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "                if is_speed_limit(tag):\n",
    "                    audit_speed_limit(speed_limits, tag.attrib['v'])\n",
    "                if is_post_code(tag):\n",
    "                    audit_post_code(post_codes, tag.attrib['v'])\n",
    "                if is_direction_suffix(tag):\n",
    "                    audit_direction_suffix(name_directions, tag.attrib['v'])\n",
    "    print \"Streets to be corrected\"\n",
    "    pprint.pprint (dict(street_types))\n",
    "    print \n",
    "    print \"mph abbreviations to be corrected\"\n",
    "    pprint.pprint (dict(speed_limits))\n",
    "    print\n",
    "    print \"post codes to be corrected\"\n",
    "    pprint.pprint (dict(post_codes))\n",
    "    print\n",
    "    print \"name direction suffix to be corrected\"\n",
    "    pprint.pprint (dict(name_directions))\n",
    "        \n",
    "##########################\n",
    "## Updates\n",
    "##########################\n",
    "def update_name(name, mapping):\n",
    "    m = street_type_re.search(name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            if street_type in mapping:\n",
    "                name = re.sub(street_type_re, mapping[street_type],name)          \n",
    "    return name\n",
    "\n",
    "def update_post_code(post_code):\n",
    "    expected = int(5)\n",
    "    if len(post_code) != expected:\n",
    "        post_code = post_code[:expected]\n",
    "    return post_code\n",
    "\n",
    "\n",
    "def update_speed_limit(speed_name):\n",
    "    expected = 'mph'\n",
    "    if speed_name[-3:] != 'mph':\n",
    "        speed_name = speed_name + \" \" + expected\n",
    "    return speed_name\n",
    "\n",
    "## Audit Call for all conditions    \n",
    "audit(OSM_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "235d8b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "    'node': {\n",
    "        'type': 'dict',\n",
    "        'schema': {\n",
    "            'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'lat': {'required': True, 'type': 'float', 'coerce': float},\n",
    "            'lon': {'required': True, 'type': 'float', 'coerce': float},\n",
    "            'user': {'required': True, 'type': 'string'},\n",
    "            'uid': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'version': {'required': True, 'type': 'string'},\n",
    "            'changeset': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'timestamp': {'required': True, 'type': 'string'}\n",
    "        }\n",
    "    },\n",
    "    'node_tags': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'key': {'required': True, 'type': 'string'},\n",
    "                'value': {'required': True, 'type': 'string'},\n",
    "                'type': {'required': True, 'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'way': {\n",
    "        'type': 'dict',\n",
    "        'schema': {\n",
    "            'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'user': {'required': True, 'type': 'string'},\n",
    "            'uid': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'version': {'required': True, 'type': 'string'},\n",
    "            'changeset': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'timestamp': {'required': True, 'type': 'string'}\n",
    "        }\n",
    "    },\n",
    "    'way_nodes': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'node_id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'position': {'required': True, 'type': 'integer', 'coerce': int}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'way_tags': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'key': {'required': True, 'type': 'string'},\n",
    "                'value': {'required': True, 'type': 'string'},\n",
    "                'type': {'required': True, 'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cf817c",
   "metadata": {},
   "source": [
    "## Data Shaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7dcd0570",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "SCHEMA = schema\n",
    "\n",
    "def tag_func(t,element, default_tag_type='regular',problem_chars=PROBLEMCHARS, lower_colon = LOWER_COLON):\n",
    "    \"\"\" Clean and shape way and node tags within shape element function \"\"\"\n",
    "    \n",
    "    if problem_chars.search(t.attrib['k']):\n",
    "            pass\n",
    "\n",
    "    else:\n",
    "        tag ={} \n",
    "        tag['id'] = element.attrib['id']\n",
    "        tag['value'] = t.attrib['v']\n",
    "        \n",
    "        if is_street_name(t):#correct the street names\n",
    "            tag['value'] = update_name(tag['value'],mapping) \n",
    "            \n",
    "        if is_post_code(t):#correct enlongated post codes to unify with majority \n",
    "            tag['value'] = update_post_code(tag['value']) \n",
    "            \n",
    "        if is_speed_limit(t):#add mph to all speed limit values\n",
    "            tag['value'] = update_speed_limit(tag['value'])\n",
    "                              \n",
    "        if lower_colon.match(t.attrib['k']):\n",
    "            k = t.attrib['k'].split(':',1)\n",
    "            tag['type'] = k[0]\n",
    "            tag['key'] = k[1]   \n",
    "\n",
    "        else:\n",
    "            tag['type'] = default_tag_type\n",
    "            tag['key'] = t.attrib['k']\n",
    "        tags.append(tag)\n",
    "\n",
    "        return tags\n",
    "\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "    \n",
    "    global tags\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    tag = {}\n",
    "    way_nodes = []\n",
    "    tags = []  \n",
    "     \n",
    "## Node\n",
    "\n",
    "    if element.tag == 'node':\n",
    "        for i in node_attr_fields:\n",
    "            node_attribs[i] = element.attrib[i] \n",
    "               \n",
    "        for t in element.iter('tag'):\n",
    "            value = tag_func(t,element)\n",
    "            if value == None:\n",
    "                break\n",
    "            else: \n",
    "                tags = value\n",
    "            \n",
    "        return({'node': node_attribs, 'node_tags': tags})\n",
    "                \n",
    "## Way   \n",
    "        \n",
    "    elif element.tag == 'way':\n",
    "        for i in way_attr_fields:\n",
    "            way_attribs[i] = element.attrib[i]\n",
    "            tag['id'] = element.attrib['id']\n",
    "            \n",
    "        ndTagCt = 0 \n",
    "        for n in element.iter('nd'):\n",
    "            w_nd = {}\n",
    "            w_nd['id'] = element.attrib['id'] #grabs the primary id of the element\n",
    "            w_nd['node_id'] = n.attrib['ref']\n",
    "            w_nd['position'] = ndTagCt\n",
    "            way_nodes.append(w_nd)\n",
    "            ndTagCt += 1\n",
    "            \n",
    "        for t in element.iter('tag'):  \n",
    "            value = tag_func(t,element)\n",
    "            if value == None:\n",
    "                break\n",
    "            else: \n",
    "                tags = value\n",
    "            \n",
    "                \n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}  \n",
    "    \n",
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_string = pprint.pformat(errors)\n",
    "        \n",
    "        raise Exception(message_string.format(field, error_string))\n",
    "\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "            \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Note: Validation is ~ 10X slower. For the project consider using a small\n",
    "    # sample of the map when validating.\n",
    "    process_map(OSM_PATH, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50449eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ab99cf-e859-4684-8049-f58692beb54c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
